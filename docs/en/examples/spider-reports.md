# Spider Report Examples

This page demonstrates how to use EmailWidget to create professional monitoring reports for web scraping and data collection projects.

## Spider Task Monitoring

### Data Collection Progress Tracking

```python
from datetime import datetime, timedelta
import random
from email_widget import Email, ProgressWidget, TableWidget, StatusWidget
from email_widget.core.enums import TextType, ProgressTheme, StatusType

# Simulate spider task data
spider_tasks = [
    {
        'name': 'E-commerce Product Info Collection',
        'target_count': 10000,
        'completed_count': 8500,
        'success_rate': 95.2,
        'avg_speed': 120,  # records/minute
        'status': 'Running',
        'start_time': datetime.now() - timedelta(hours=2)
    },
    {
        'name': 'News Article Scraping',
        'target_count': 5000,
        'completed_count': 5000,
        'success_rate': 98.8,
        'avg_speed': 200,
        'status': 'Completed',
        'start_time': datetime.now() - timedelta(hours=1, minutes=30)
    },
    {
        'name': 'User Review Data',
        'target_count': 20000,
        'completed_count': 12000,
        'success_rate': 92.1,
        'avg_speed': 80,
        'status': 'Running',
        'start_time': datetime.now() - timedelta(hours=3)
    }
]

# Create spider monitoring report
email = Email("Spider Task Monitoring Report")

email.add_title("üï∑Ô∏è Spider Task Monitoring Report", TextType.TITLE_LARGE)
email.add_text(f"Report Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

# Task overview statistics
email.add_title("üìä Task Overview", TextType.SECTION_H2)

total_tasks = len(spider_tasks)
running_tasks = sum(1 for task in spider_tasks if task['status'] == 'Running')
completed_tasks = sum(1 for task in spider_tasks if task['status'] == 'Completed')
total_collected = sum(task['completed_count'] for task in spider_tasks)

overview_stats = [
    ("Total Tasks", f"{total_tasks}", "üéØ"),
    ("Running", f"{running_tasks}", "üîÑ"),
    ("Completed", f"{completed_tasks}", "‚úÖ"),
    ("Total Collected", f"{total_collected:,}", "üì¶")
]

for title, value, icon in overview_stats:
    email.add_card(title=title, content=value, icon=icon)

# Detailed progress for each task
email.add_title("üìà Task Progress Details", TextType.SECTION_H2)

for task in spider_tasks:
    # Calculate progress percentage
    progress_percent = (task['completed_count'] / task['target_count']) * 100
    
    # Set theme color based on status
    if task['status'] == 'Completed':
        theme = ProgressTheme.SUCCESS
        status_type = StatusType.SUCCESS
    elif task['success_rate'] > 95:
        theme = ProgressTheme.INFO
        status_type = StatusType.SUCCESS
    elif task['success_rate'] > 90:
        theme = ProgressTheme.WARNING
        status_type = StatusType.WARNING
    else:
        theme = ProgressTheme.ERROR
        status_type = StatusType.ERROR
    
    # Task status card
    status_widget = StatusWidget()
    status_widget.set_title(task['name']) \
                 .set_status(task['status']) \
                 .set_status_type(status_type) \
                 .set_description(f"Success Rate: {task['success_rate']:.1f}% | Speed: {task['avg_speed']} records/min")
    email.add_widget(status_widget)
    
    # Progress bar
    email.add_progress(
        value=progress_percent,
        label=f"{task['completed_count']:,}/{task['target_count']:,} ({progress_percent:.1f}%)",
        theme=theme
    )

# Detailed data table
email.add_title("üìã Detailed Task Data", TextType.SECTION_H2)

table = TableWidget()
table.set_headers(["Task Name", "Target Count", "Completed", "Completion Rate", "Success Rate", "Avg Speed", "Runtime"])

for task in spider_tasks:
    runtime = datetime.now() - task['start_time']
    runtime_str = f"{runtime.seconds // 3600}h {(runtime.seconds % 3600) // 60}m"
    
    progress_percent = (task['completed_count'] / task['target_count']) * 100
    
    table.add_row([
        task['name'],
        f"{task['target_count']:,}",
        f"{task['completed_count']:,}",
        f"{progress_percent:.1f}%",
        f"{task['success_rate']:.1f}%",
        f"{task['avg_speed']} records/min",
        runtime_str
    ])

table.set_striped(True)
email.add_widget(table)

# Performance analysis
email.add_title("‚ö° Performance Analysis", TextType.SECTION_H2)

avg_success_rate = sum(task['success_rate'] for task in spider_tasks) / len(spider_tasks)
fastest_task = max(spider_tasks, key=lambda x: x['avg_speed'])
slowest_task = min(spider_tasks, key=lambda x: x['avg_speed'])

performance_text = f"""
**Spider Performance Analysis:**

üìä **Overall Performance**
‚Ä¢ Average Success Rate: {avg_success_rate:.1f}%
‚Ä¢ Fastest Task: {fastest_task['name']} ({fastest_task['avg_speed']} records/min)
‚Ä¢ Slowest Task: {slowest_task['name']} ({slowest_task['avg_speed']} records/min)

üí° **Optimization Recommendations**
‚Ä¢ Tasks with success rate below 90% need anti-scraping strategy review
‚Ä¢ Consider adjusting concurrency to improve collection speed
‚Ä¢ Monitor target website response time changes
"""

email.add_text(performance_text.strip())

email.export_html("spider_monitor.html")
print("‚úÖ Spider monitoring report generated: spider_monitor.html")
```

--8<-- "examples/assets/spider_reports_html/spider_monitor.html"

**Monitoring Features:**
- Real-time task progress tracking
- Success rate and speed monitoring
- Multi-task status aggregation
- Performance analysis and optimization recommendations

---

## Data Quality Report

### Collected Data Quality Check

```python
import pandas as pd
from email_widget import Email, TableWidget, AlertWidget, ProgressWidget
from email_widget.core.enums import TextType, AlertType, ProgressTheme

# Simulate collected data quality statistics
data_quality_stats = {
    'total_records': 50000,
    'valid_records': 47500,
    'duplicate_records': 1200,
    'incomplete_records': 800,
    'invalid_format': 500,
    'fields_quality': {
        'Title': {'completeness': 98.5, 'validity': 99.2},
        'Price': {'completeness': 95.2, 'validity': 92.8},
        'Image URL': {'completeness': 89.3, 'validity': 88.1},
        'Description': {'completeness': 78.6, 'validity': 95.4},
        'Rating': {'completeness': 92.1, 'validity': 98.7}
    }
}

# Create data quality report
email = Email("Data Quality Check Report")

email.add_title("üîç Data Quality Check Report", TextType.TITLE_LARGE)
email.add_text(f"Data Check Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

# Data quality overview
email.add_title("üìä Data Quality Overview", TextType.SECTION_H2)

total = data_quality_stats['total_records']
valid = data_quality_stats['valid_records']
duplicate = data_quality_stats['duplicate_records']
incomplete = data_quality_stats['incomplete_records']
invalid = data_quality_stats['invalid_format']

quality_rate = (valid / total) * 100
duplicate_rate = (duplicate / total) * 100

quality_overview = [
    ("Total Records", f"{total:,}", "üì¶"),
    ("Valid Records", f"{valid:,}", "‚úÖ"),
    ("Data Quality Rate", f"{quality_rate:.1f}%", "üéØ"),
    ("Duplicate Rate", f"{duplicate_rate:.1f}%", "üîÑ")
]

for title, value, icon in quality_overview:
    email.add_card(title=title, content=value, icon=icon)

# Detailed data quality analysis
email.add_title("üìà Quality Metrics Analysis", TextType.SECTION_H2)

# Overall quality score
overall_quality = (valid / total) * 100
quality_theme = ProgressTheme.SUCCESS if overall_quality > 95 else \
               ProgressTheme.WARNING if overall_quality > 90 else ProgressTheme.ERROR

email.add_text("üîπ Overall Data Quality")
email.add_progress(overall_quality, f"Quality Rate: {overall_quality:.1f}%", theme=quality_theme)

# Duplicate data rate
dup_theme = ProgressTheme.SUCCESS if duplicate_rate < 2 else \
           ProgressTheme.WARNING if duplicate_rate < 5 else ProgressTheme.ERROR

email.add_text("üîπ Duplicate Data Ratio")
email.add_progress(duplicate_rate, f"Duplicate Rate: {duplicate_rate:.1f}%", theme=dup_theme)

# Field quality details
email.add_title("üîç Field Quality Details", TextType.SECTION_H2)

field_table = TableWidget()
field_table.set_headers(["Field Name", "Completeness", "Validity", "Quality Grade"])

for field_name, quality in data_quality_stats['fields_quality'].items():
    completeness = quality['completeness']
    validity = quality['validity']
    avg_quality = (completeness + validity) / 2
    
    # Quality grade
    if avg_quality >= 95:
        grade = "üü¢ Excellent"
    elif avg_quality >= 90:
        grade = "üü° Good"
    elif avg_quality >= 80:
        grade = "üü† Average"
    else:
        grade = "üî¥ Poor"
    
    field_table.add_row([
        field_name,
        f"{completeness:.1f}%",
        f"{validity:.1f}%",
        grade
    ])

field_table.set_striped(True)
email.add_widget(field_table)

# Data issue statistics
email.add_title("‚ö†Ô∏è Data Issue Statistics", TextType.SECTION_H2)

problem_table = TableWidget()
problem_table.set_headers(["Issue Type", "Record Count", "Percentage", "Impact Level"])

problems = [
    ("Duplicate Records", duplicate, (duplicate/total)*100, "Medium"),
    ("Incomplete Records", incomplete, (incomplete/total)*100, "High"),
    ("Format Errors", invalid, (invalid/total)*100, "High"),
]

for problem_type, count, percentage, impact in problems:
    impact_emoji = "üü¢" if impact == "Low" else "üü°" if impact == "Medium" else "üî¥"
    problem_table.add_row([
        problem_type,
        f"{count:,}",
        f"{percentage:.1f}%",
        f"{impact_emoji} {impact}"
    ])

problem_table.set_striped(True)
email.add_widget(problem_table)

# Quality improvement recommendations
email.add_title("üí° Quality Improvement Recommendations", TextType.SECTION_H2)

# Generate recommendations based on data quality
if overall_quality < 90:
    email.add_alert(
        "Data quality below 90%, recommend immediate optimization of spider logic and data cleaning process",
        AlertType.CAUTION,
        "üö® Quality Alert"
    )

if duplicate_rate > 5:
    email.add_alert(
        f"Duplicate data rate reached {duplicate_rate:.1f}%, recommend enhancing deduplication mechanism",
        AlertType.WARNING,
        "‚ö†Ô∏è Duplicate Data Alert"
    )

# Improvement suggestions
improvement_suggestions = f"""
**Data Quality Improvement Recommendations:**

üîß **Technical Improvements**
‚Ä¢ Strengthen data validation rules to improve field validity
‚Ä¢ Optimize deduplication algorithms to reduce duplicate data rate
‚Ä¢ Improve exception handling to reduce incomplete records

üìä **Quality Monitoring**
‚Ä¢ Set quality threshold alerts (recommended: quality rate >95%, duplicate rate <2%)
‚Ä¢ Real-time monitoring of key field completeness
‚Ä¢ Regular data quality assessments

‚ö° **Process Optimization**
‚Ä¢ Perform quality checks before data insertion
‚Ä¢ Establish data quality scoring system
‚Ä¢ Automate data cleaning and repair processes
"""

email.add_text(improvement_suggestions.strip())

email.export_html("data_quality_report.html")
print("‚úÖ Data quality report generated: data_quality_report.html")
```

--8<-- "examples/assets/spider_reports_html/data_quality_report.html"

**Quality Check Features:**
- Multi-dimensional quality assessment
- Field-level quality analysis
- Automated issue identification
- Improvement recommendation generation

---

## Exception Monitoring Report

### Spider Exception and Error Analysis

```python
from collections import Counter
from email_widget import Email, ChartWidget, TableWidget, AlertWidget
from email_widget.core.enums import TextType, AlertType
import matplotlib.pyplot as plt

# Simulate spider exception data
spider_errors = [
    {'timestamp': '2024-01-20 10:15', 'error_type': 'HTTP_TIMEOUT', 'url': 'example1.com', 'message': 'Request timeout'},
    {'timestamp': '2024-01-20 10:16', 'error_type': 'PARSING_ERROR', 'url': 'example2.com', 'message': 'Parsing failed'},
    {'timestamp': '2024-01-20 10:17', 'error_type': 'HTTP_404', 'url': 'example3.com', 'message': 'Page not found'},
    {'timestamp': '2024-01-20 10:18', 'error_type': 'RATE_LIMITED', 'url': 'example4.com', 'message': 'Request rate limited'},
    {'timestamp': '2024-01-20 10:19', 'error_type': 'HTTP_TIMEOUT', 'url': 'example5.com', 'message': 'Connection timeout'},
    {'timestamp': '2024-01-20 10:20', 'error_type': 'CAPTCHA_DETECTED', 'url': 'example6.com', 'message': 'Captcha detected'},
    {'timestamp': '2024-01-20 10:21', 'error_type': 'PARSING_ERROR', 'url': 'example7.com', 'message': 'Data structure changed'},
    {'timestamp': '2024-01-20 10:22', 'error_type': 'HTTP_403', 'url': 'example8.com', 'message': 'Access forbidden'},
]

# Create exception monitoring report
email = Email("Spider Exception Monitoring Report")

email.add_title("üö® Spider Exception Monitoring Report", TextType.TITLE_LARGE)
email.add_text(f"Exception Statistics Time: Last 1 hour")

# Exception statistics overview
error_counts = Counter(error['error_type'] for error in spider_errors)
total_errors = len(spider_errors)

email.add_title("üìä Exception Statistics Overview", TextType.SECTION_H2)

error_overview = [
    ("Total Exceptions", f"{total_errors}", "üö®"),
    ("Exception Types", f"{len(error_counts)}", "üîç"),
    ("Most Common", f"{error_counts.most_common(1)[0][0]}", "‚ö†Ô∏è"),
    ("Time Range", "Last 1 hour", "‚è∞")
]

for title, value, icon in error_overview:
    email.add_card(title=title, content=value, icon=icon)

# Exception type distribution
email.add_title("üìà Exception Type Distribution", TextType.SECTION_H2)

# Create exception distribution chart
plt.figure(figsize=(10, 6))
error_types = list(error_counts.keys())
error_values = list(error_counts.values())

bars = plt.bar(error_types, error_values, color=['#e74c3c', '#f39c12', '#3498db', '#9b59b6', '#1abc9c', '#95a5a6'])
plt.title('Exception Type Distribution', fontsize=14)
plt.xlabel('Exception Type')
plt.ylabel('Occurrence Count')
plt.xticks(rotation=45)

# Add value labels
for bar, value in zip(bars, error_values):
    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1, 
             str(value), ha='center', va='bottom')

plt.tight_layout()
error_chart_path = "spider_errors_distribution.png"
plt.savefig(error_chart_path, dpi=150, bbox_inches='tight')
plt.close()

chart = ChartWidget()
chart.set_chart_path(error_chart_path) \
     .set_title("Exception Type Distribution Chart") \
     .set_description("Shows occurrence frequency of each exception type")
email.add_widget(chart)

# Exception details table
email.add_title("üìã Exception Details List", TextType.SECTION_H2)

error_table = TableWidget()
error_table.set_headers(["Time", "Exception Type", "Target URL", "Error Message"])

for error in spider_errors[-10:]:  # Show last 10 exceptions
    error_table.add_row([
        error['timestamp'],
        error['error_type'],
        error['url'][:30] + "..." if len(error['url']) > 30 else error['url'],
        error['message']
    ])

error_table.set_striped(True)
email.add_widget(error_table)

# Exception analysis and recommendations
email.add_title("üí° Exception Analysis and Recommendations", TextType.SECTION_H2)

# Generate alerts and recommendations based on exception types
critical_errors = ['RATE_LIMITED', 'CAPTCHA_DETECTED', 'HTTP_403']
timeout_errors = ['HTTP_TIMEOUT']
parsing_errors = ['PARSING_ERROR']

for error_type, count in error_counts.items():
    if error_type in critical_errors:
        email.add_alert(
            f"{error_type} occurred {count} times, may have triggered anti-scraping mechanism",
            AlertType.CAUTION,
            f"üö® {error_type} Alert"
        )
    elif error_type in timeout_errors and count > 3:
        email.add_alert(
            f"Frequent timeout errors ({count} times), recommend checking network connection and timeout settings",
            AlertType.WARNING,
            "‚ö†Ô∏è Timeout Alert"
        )

analysis_text = f"""
**Exception Analysis Results:**

üîç **Main Issues**
‚Ä¢ {error_counts.most_common(1)[0][0]} is the most frequent exception type ({error_counts.most_common(1)[0][1]} times)
‚Ä¢ Total exception rate needs attention, recommend optimizing spider strategy

üõ†Ô∏è **Solutions**
"""

# Provide recommendations for different exception types
if 'HTTP_TIMEOUT' in error_counts:
    analysis_text += f"\n‚Ä¢ Timeout exceptions ({error_counts['HTTP_TIMEOUT']} times): Increase timeout duration, optimize network connection"

if 'RATE_LIMITED' in error_counts:
    analysis_text += f"\n‚Ä¢ Rate limit exceptions ({error_counts['RATE_LIMITED']} times): Reduce request frequency, increase proxy pool"

if 'CAPTCHA_DETECTED' in error_counts:
    analysis_text += f"\n‚Ä¢ Captcha exceptions ({error_counts['CAPTCHA_DETECTED']} times): Integrate captcha recognition service"

if 'PARSING_ERROR' in error_counts:
    analysis_text += f"\n‚Ä¢ Parsing exceptions ({error_counts['PARSING_ERROR']} times): Update parsing rules, enhance error tolerance"

analysis_text += f"""

‚ö° **Optimization Measures**
‚Ä¢ Implement intelligent retry mechanism
‚Ä¢ Add exception handling logic
‚Ä¢ Monitor target website changes
‚Ä¢ Regularly update spider strategies
"""

email.add_text(analysis_text.strip())

email.export_html("spider_error_analysis.html")
print("‚úÖ Spider exception analysis report generated: spider_error_analysis.html")
```

--8<-- "examples/assets/spider_reports_html/spider_error_analysis.html"

**Exception Monitoring Highlights:**
- Exception type statistical analysis
- Visual exception distribution
- Intelligent alert mechanism
- Targeted solution recommendations

---

## Collection Efficiency Optimization

### Spider Performance Analysis Report

```python
from email_widget import Email, ProgressWidget, TableWidget
from email_widget.core.enums import TextType, ProgressTheme

# Spider performance data
performance_data = {
    'spider_configs': [
        {'name': 'Single Thread Mode', 'threads': 1, 'success_rate': 98.5, 'speed': 50, 'cpu_usage': 15, 'memory_mb': 128},
        {'name': 'Multi Thread Mode', 'threads': 5, 'success_rate': 95.2, 'speed': 200, 'cpu_usage': 45, 'memory_mb': 512},
        {'name': 'Async Mode', 'threads': 10, 'success_rate': 92.8, 'speed': 450, 'cpu_usage': 35, 'memory_mb': 256},
        {'name': 'Distributed Mode', 'threads': 20, 'success_rate': 89.1, 'speed': 800, 'cpu_usage': 25, 'memory_mb': 1024}
    ]
}

# Create performance analysis report
email = Email("Spider Performance Optimization Analysis")

email.add_title("‚ö° Spider Performance Optimization Analysis", TextType.TITLE_LARGE)

# Performance configuration comparison overview
email.add_title("üìä Performance Configuration Comparison", TextType.SECTION_H2)

perf_table = TableWidget()
perf_table.set_headers(["Configuration Mode", "Threads", "Success Rate", "Collection Speed", "CPU Usage", "Memory Usage"])

for config in performance_data['spider_configs']:
    perf_table.add_row([
        config['name'],
        str(config['threads']),
        f"{config['success_rate']:.1f}%",
        f"{config['speed']} records/min",
        f"{config['cpu_usage']}%",
        f"{config['memory_mb']} MB"
    ])

perf_table.set_striped(True)
email.add_widget(perf_table)

# Detailed analysis for each configuration
email.add_title("üîç Detailed Configuration Analysis", TextType.SECTION_H2)

for config in performance_data['spider_configs']:
    email.add_text(f"üìã {config['name']}")
    
    # Success rate progress bar
    success_theme = ProgressTheme.SUCCESS if config['success_rate'] > 95 else \
                   ProgressTheme.WARNING if config['success_rate'] > 90 else ProgressTheme.ERROR
    
    # Efficiency score (considering both speed and success rate)
    efficiency_score = (config['speed'] / 10) * (config['success_rate'] / 100)
    efficiency_percent = min(efficiency_score, 100)
    
    email.add_progress(config['success_rate'], f"Success Rate: {config['success_rate']:.1f}%", theme=success_theme)
    email.add_progress(efficiency_percent, f"Efficiency Score: {efficiency_score:.1f}", theme=ProgressTheme.INFO)

# Optimization recommendations
email.add_title("üí° Performance Optimization Recommendations", TextType.SECTION_H2)

# Find best configuration
best_config = max(performance_data['spider_configs'], 
                 key=lambda x: (x['speed'] / 10) * (x['success_rate'] / 100))

optimization_text = f"""
**Performance Optimization Analysis Results:**

üèÜ **Recommended Configuration**
‚Ä¢ Best overall performance: {best_config['name']}
‚Ä¢ Collection speed: {best_config['speed']} records/min
‚Ä¢ Success rate: {best_config['success_rate']:.1f}%
‚Ä¢ Resource consumption: CPU {best_config['cpu_usage']}%, Memory {best_config['memory_mb']}MB

‚öñÔ∏è **Configuration Trade-offs**
‚Ä¢ Single Thread Mode: High success rate, low resource consumption, suitable for small-scale collection
‚Ä¢ Multi Thread Mode: Balanced performance, suitable for medium-scale projects
‚Ä¢ Async Mode: High efficiency low resource, suitable for large-scale fast collection
‚Ä¢ Distributed Mode: Ultra-high speed, suitable for massive projects

üéØ **Optimization Recommendations**
‚Ä¢ Choose appropriate concurrency mode based on target website characteristics
‚Ä¢ Monitor success rate changes, adjust concurrency timely
‚Ä¢ Find optimal balance between speed and stability
‚Ä¢ Consider website anti-scraping strategies, avoid overly aggressive configurations
"""

email.add_text(optimization_text.strip())

email.export_html("spider_performance_analysis.html")
print("‚úÖ Spider performance analysis report generated: spider_performance_analysis.html")
```

--8<-- "examples/assets/spider_reports_html/spider_performance_analysis.html"

**Performance Analysis Features:**
- Multi-dimensional performance comparison
- Comprehensive efficiency scoring
- Resource consumption analysis
- Configuration optimization recommendations

---

## Data Collection Summary

### Complete Spider Project Report

```python
from email_widget import Email, ColumnWidget, StatusWidget, CardWidget
from email_widget.core.enums import TextType, StatusType

# Create comprehensive spider project report
email = Email("Spider Project Comprehensive Report")

email.add_title("üï∑Ô∏è Spider Project Comprehensive Report", TextType.TITLE_LARGE)
email.add_text(f"Project Period: January 15, 2024 - January 21, 2024")

# Project overall overview
email.add_title("üìä Project Overall Overview", TextType.SECTION_H2)

project_summary = [
    ("Target Websites", "15", "üåê"),
    ("Total Collected", "125,000 records", "üì¶"),
    ("Average Success Rate", "94.3%", "‚úÖ"),
    ("Data Quality Rate", "92.8%", "üéØ")
]

for title, value, icon in project_summary:
    email.add_card(title=title, content=value, icon=icon)

# Key achievements showcase
email.add_title("üèÜ Key Achievements", TextType.SECTION_H2)

achievements = f"""
**Project Main Achievements:**

‚úÖ **Collection Results**
‚Ä¢ Successfully completed data collection from 15 target websites
‚Ä¢ Accumulated 125,000 valid data records
‚Ä¢ Data coverage reached 105% of expected target

üéØ **Quality Assurance**
‚Ä¢ Data quality rate 92.8%, exceeding expected 90%
‚Ä¢ Duplicate data rate controlled within 2.1%
‚Ä¢ Key field completeness above 95%

‚ö° **Technical Breakthroughs**
‚Ä¢ Successfully handled 5 different anti-scraping mechanisms
‚Ä¢ Developed intelligent retry and fallback strategies
‚Ä¢ Implemented distributed collection architecture

üìà **Efficiency Improvement**
‚Ä¢ 300% efficiency improvement compared to traditional methods
‚Ä¢ Exception handling mechanism reduced manual intervention by 80%
‚Ä¢ Automation level reached 95%
"""

email.add_text(achievements.strip())

# Experience summary
email.add_title("üí° Experience Summary", TextType.SECTION_H2)

lessons_learned = f"""
**Project Experience and Lessons:**

üéì **Successful Experience**
‚Ä¢ Thorough preliminary research and technology selection
‚Ä¢ Comprehensive monitoring and alert mechanisms
‚Ä¢ Flexible strategy adjustment and optimization

üöß **Challenges Encountered**
‚Ä¢ Target websites frequently updated anti-scraping strategies
‚Ä¢ Data structure changes required timely adaptation
‚Ä¢ Resource management optimization under high concurrency

üîÑ **Continuous Improvement**
‚Ä¢ Establish website change monitoring mechanism
‚Ä¢ Improve automated testing processes
‚Ä¢ Optimize data quality check rules
"""

email.add_text(lessons_learned.strip())

email.export_html("spider_project_summary.html")
print("‚úÖ Spider project comprehensive report generated: spider_project_summary.html")
```

--8<-- "examples/assets/spider_reports_html/spider_project_summary.html"

**Comprehensive Report Value:**
- Complete project overview
- Quantified achievement statistics
- Experience summary and insights
- Decision support information

---

## Learning Summary

Through spider report examples, you have mastered:

### üéØ Professional Skills
- **Task Monitoring** - Real-time progress tracking and status management
- **Quality Check** - Multi-dimensional data quality assessment
- **Exception Analysis** - Intelligent exception identification and handling recommendations
- **Performance Optimization** - Configuration comparison and efficiency analysis

### üìä Report Types
- Spider task progress reports
- Data quality check reports
- Exception monitoring analysis reports
- Performance optimization analysis reports

### üí° Best Practices
- Real-time monitoring and alert mechanisms
- Data-driven optimization decisions
- Automated exception detection and handling
- Visual display of complex data relationships

### üöÄ Application Value
- Improve spider project management efficiency
- Ensure data collection quality
- Timely discovery and problem resolution
- Provide basis for technical optimization

Continue learning [Real Applications](real-world.md) to explore more professional application scenarios!